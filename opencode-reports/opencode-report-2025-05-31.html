<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>opencode-report-2025-05-31</title>
  <style>
    body { font-family: Menlo, Monaco, monospace; background: #f5f5f7; color: #222; margin: 0; padding: 2em; }
    h1, h2, h3 { color: #445; }
    pre { background: #23252b; color: #f5f5f5; padding: 1em; border-radius: 6px; overflow-x: auto; font-size: 14px; }
    section { margin-bottom: 2.5em; }
    .file-name { font-weight: bold; margin-bottom: 0.3em; font-size: 1.05em; color: #4078c0; }
    .date { color: #666; font-size: 0.98em; float: right; }
  </style>
</head>
<body>
  <h1>OpenCode Integration Report</h1>
  <div class="date">Generated: 2025-05-31</div>
  <section>
    <h2>Summary</h2>
    <p>This report documents the changes implemented to provide a persistent, centralized Puppeteer job queue (via PostgreSQL and Drizzle ORM) to coordinate browser scraping requests from any backend module. The new logic guarantees only one Puppeteer job runs at a time, regardless of user or app, and that jobs persist through server restarts for robustness.</p>
  </section>

  <section>
    <h2>Queue Flow &amp; Integration</h2>
    <p><b>Flow overview:</b></p>
    <ol>
      <li>Each Puppeteer scraping request is enqueued into a database table before any browser automation begins.</li>
      <li>If a job is already running, the new job waits (with polling) until the running job completes.</li>
      <li>When the job gets its turn, it updates its status atomically to <code>running</code> and begins.</li>
      <li>On completion (or error), the job updates its status to <code>done</code> (or <code>failed</code>).</li>
    </ol>
    <p>All integration is minimal and occurs at the <b>boundary</b> before starting Puppeteer logic. All browser and scraping details remain untouched.</p>
  </section>

  <section>
    <h2>New &amp; Modified Files</h2>
    <div class="file-name">shared/db/schema/puppeteer-job-queue.ts</div>
    <pre>// Drizzle schema for persistent Puppeteer job queue
import { pgTable, uuid, timestamp, text, jsonb } from 'drizzle-orm/pg-core';
import { users } from './user';

export const puppeteerJobQueue = pgTable('puppeteer_job_queue', {
  id: uuid('id').defaultRandom().primaryKey(),
  createdAt: timestamp('created_at').notNull().defaultNow(),
  updatedAt: timestamp('updated_at'),
  status: text('status').notNull(), // 'queued', 'running', 'done', 'failed'
  userId: uuid('user_id').references(() => users.id),
  sourceApp: text('source_app'),
  inputData: jsonb('input_data').notNull(),
  outputData: jsonb('output_data'),
  runAt: timestamp('run_at'),
});
</pre>

    <div class="file-name">shared/db/puppeteer-queue.ts</div>
    <pre>// Utility for queueing Puppeteer jobs and coordinating their execution
import { eq, and } from "drizzle-orm";
import { db } from "./db";
import { puppeteerJobQueue } from "./schema/puppeteer-job-queue";
import { users } from "./schema/user";

export async function enqueuePuppeteerJob({ inputData, userId, sourceApp }) {
  const [job] = await db.insert(puppeteerJobQueue).values({
    status: 'queued', userId, sourceApp, inputData,
  }).returning();
  return job;
}

export async function tryStartJob(jobId) {
  const result = await db.update(puppeteerJobQueue)
    .set({ status: 'running', updatedAt: new Date() })
    .where(and(
      eq(puppeteerJobQueue.id, jobId),
      eq(puppeteerJobQueue.status, 'queued'),
      db.raw('(SELECT count(*) FROM puppeteer_job_queue WHERE status = ?)',['running']).equals(0)
    ))
    .returning();
  return result.length > 0;
}

export async function waitForTurnAndStart(jobId, pollMs=1500, timeoutMs=300000) {
  const started = await tryStartJob(jobId);
  if (started) return;
  const start = Date.now();
  while (Date.now() - start < timeoutMs) {
    await new Promise(r => setTimeout(r, pollMs));
    if (await tryStartJob(jobId)) return;
  }
  throw new Error('Timeout waiting for Puppeteer job queue');
}

export async function markJobDone(jobId, outputData) {
  await db.update(puppeteerJobQueue)
      .set({ status: 'done', outputData, updatedAt: new Date() })
      .where(eq(puppeteerJobQueue.id, jobId));
}

export async function markJobFailed(jobId, error) {
  await db.update(puppeteerJobQueue)
      .set({ status: 'failed', outputData: {error: String(error)}, updatedAt: new Date() })
      .where(eq(puppeteerJobQueue.id, jobId));
}

export async function runQueuedPuppeteerJob({inputData, userId, sourceApp, fn}) {
  const job = await enqueuePuppeteerJob({ inputData, userId, sourceApp });
  await waitForTurnAndStart(job.id);
  try {
    const result = await fn(job.id);
    await markJobDone(job.id, result);
    return result;
  } catch (e) {
    await markJobFailed(job.id, e);
    throw e;
  }
}
</pre>

    <div class="file-name">backend/apps/news-radar/services/puppeteer-scraper.ts</div>
    <pre>... // imports
import { runQueuedPuppeteerJob } from 'shared/db/puppeteer-queue';
...
export async function scrapePuppeteer(
  url: string,
  isArticlePage: boolean = false,
  scrapingConfig: any,
  queueOptions?: { userId?: string }
): Promise&lt;string&gt; {
  return runQueuedPuppeteerJob({
    inputData: { url, isArticlePage, scrapingConfig },
    userId: queueOptions?.userId,
    sourceApp: 'news-radar',
    fn: async () =&gt; {
      // ...browser scraping code (unchanged)...
    }
  });
}
</pre>

    <div class="file-name">backend/apps/threat-tracker/services/scraper.ts</div>
    <pre>... // imports
import { runQueuedPuppeteerJob } from 'shared/db/puppeteer-queue';
...
export async function scrapeUrl(
  url: string,
  isArticlePage: boolean = false,
  scrapingConfig?: any,
  queueOptions?: { userId?: string }
): Promise&lt;string&gt; {
  return runQueuedPuppeteerJob({
    inputData: { url, isArticlePage, scrapingConfig },
    userId: queueOptions?.userId,
    sourceApp: 'threat-tracker',
    fn: async () =&gt; {
      // ...browser scraping code (unchanged)...
    }
  });
}
</pre>

  </section>

  <section>
    <h2>How to Use / Extend</h2>
    <ul>
      <li>Scraper jobs are now automatically queued and coordinated anywhere they use the queue utility.</li>
      <li>Queue records in the DB let you build robust admin views/monitors or retry logic for failed jobs.</li>
      <li>You can pass <code>userId</code> or <code>sourceApp</code> to the queue methods for attribution or analytics.</li>
      <li>All queue code is isolated; all browser/Puppeteer code and error handling remain just as before.</li>
    </ul>
  </section>
</body>
</html>
